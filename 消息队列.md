# **消息队列**

> https://segmentfault.com/a/1190000039274777
>
> https://zhuanlan.zhihu.com/p/151589051

## **Q：消息队列解决了哪些问题**

- **解耦**

  - 场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。订单系统与库存系统耦合，假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，

  - 解决方案：订单系统在，用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。库存系统，订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。

- **异步**

  - 场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种：串行的方式和并行方式。

    并行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户。

    串行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。

  - 解决方案：用户的响应写入数据库，写入消息队列后，直接返回，发送邮件和注册短信异步来做。

- **削峰**

  秒杀或者团购活动，流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。

## Q：消息队列存在的问题

- 系统的可用性降低
- 系统的复杂性变高
  - 重复消息
  - 消息丢失
  - 消息积压
  - 消息的顺序性
- 一致性问题

## Q：消息队列的对比

![preview](https://pic2.zhimg.com/v2-e51d18b57d05847a762194e5a3190909_r.jpg)

## Q：消息队列的高可用

### RabbtitMQ高可用

RabbitMQ有三种模式：单机模式 、普通集群模式、镜像集群模式

单机模式：Demo 级别 

普通集群模式：目标是提高吞吐量，不能保证高可用，队列的元数据存在于多个实例中，但是消息不存在多个实例中。每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

![img](https://pic2.zhimg.com/80/v2-deebfd15d1af3ca4176cbd972fbcba09_1440w.jpg)

镜像集群模式（高可用，非分布式）：

![img](https://pic3.zhimg.com/80/v2-bb208476129d322313eb2a788b8721f6_1440w.jpg)

队列的元数据和消息都会存在于多个实例中，每次写消息到 queue的时候，都会自动把消息到多个实例的 queue 里进行消息同步。也就是每个节点上都有这个 queue 的一个完整镜像（这个 queue的全部数据）。任何一个节点宕机了，其他节点还包含这个 queue的完整数据，其他 consumer 都可以到其他活着的节点上去消费数据都是 OK 的。

Kafka 高可用架构

![img](https://pic2.zhimg.com/80/v2-cf722e37884b85dcc6576918113ee3d5_1440w.jpg)

topic可以划分为多个 partition,每个 partition 可以存在于不同的 broker 上，每个 partition就存放一部分数据。Kafka 0.8以后，提供了 HA 机制，就是 replica 副本机制。

每个 partition的数据都会同步到其他机器上，形成自己的多个 replica 副本。然后所有 replica 会选举一个 leader。那么生产者、消费者都会和这个 leader 打交道，然后其他 replica 就是 follow。写的时候，leader 负责把数据同步到所有 follower上去，读的时候就直接读 leader 上的数据即可。

**leader和follower的同步机制：**

写数据的时候，生产者就写 leader，然后 leader将数据落地写本地磁盘，接着其他 follower 自己主动从 leader来pull数据。一旦所有 follower同步好数据了，就会发送 ack给 leader，leader收到所有 follower的 ack之后，就会返回写成功的消息给生产者。

消费的时候，只会从 leader去读，但是只有一个消息已经被所有 follower都同步成功返回 ack的时候，这个消息才会被消费者读到。

## 消息队列重复数据

既然是消费消息，那肯定要考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是 MQ 领域的基本问题，其实本质上还是问你**使用消息队列如何保证幂等性**

**重复消费问题的发生**

Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

Consumer直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset。重启之后，少数消息会再次消费一次。

![mq-10](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/mq-10.png)

重复消费之后，业务层面**怎么保证幂等性**

其实还是得结合业务来思考，我这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据存在，update 一下好吧。
- 比如是写 Redis，反正每次都是 set，天然幂等性。
- 你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，利用Redis set 去重。
- 基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

## 保证 MQ 消息不丢

**RabbitMQ可能存在的数据丢失问题**

- 生产者写消息的过程中，消息都没有到 rabbitmq，在网络传输过程中就丢了。
- RabbitMQ 接收到消息之后先暂存在主机的内存里，结果消费者还没来得及消费，RabbitMQ自己挂掉了，就导致暂存在内存里的数据给搞丢了。
- 消费者消费到了这个消费，但是还没来得及处理，自己就挂掉了，RabbitMQ 以为这个消费者已经处理完了。

针对三个环节丢失数据的解决方案：

**问题1**

- 事务机制：（一般不采用，同步的，生产者发送消息会同步阻塞卡住等待消息队列是否成功接收。会导致生产者发送消息的吞吐量降下来）

- confirm机制：（一般采用这种机制，异步回调的模式，不会阻塞，吞吐量会比较高）

  先把 channel 设置成 confirm 模式

  发送一个消息到 rabbitmq

  发送完消息后就不用管了

  rabbitmq 如果接收到了这条消息，就会回调你生产者本地的一个接口，通知你说这条消息我已经收到了

  rabbitmq 如果在接收消息的时候报错了，就会回调你的接口，告诉你这个消息接收失败了，你可以再次重发。

**问题2**

- 创建queue的时候将其设置为持久化的，这样就可以保证 rabbitmq持久化queue的元数据，但是不会持久化queue里的数据
- 发送消息的时候将 deliveryMode 设置为 2，将消息设置为持久化的，此时 rabbitmq就会将消息持久化到磁盘上去。必须同时设置 2 个持久化才行。
- 持久化可以跟生产者那边的 confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack了 ，所以哪怕是在持久化到磁盘之前 ，rabbitmq挂了，数据丢了，生产者收不到 ack，你也可以自己重发。

**问题3**

原因：消费者打开了 autoAck机制（消费到一条消息，还在处理中，还没处理完，此时消费者自动 autoAck了，通知 rabbitmq说这条消息已经消费了，此时不巧，消费者系统宕机了，那条消息丢失了，还没处理完，而且 rabbitmq还以为这个消息已经处理掉了）

解决方案：关闭 autoAck,自己处理完了一条消息后，再发送 ack给 rabbitmq,如果此时还没处理完就宕机了，此时rabbitmq没收到你发的ack消息，然后 rabbitmq 就会将这条消息重新分配给其他的消费者去处理。

**Kafka 可能存在的数据丢失问题**

- 消费端弄丢数据

原因：消费者消费到那条消息后，自动提交了 offset，kafka以为你已经消费好了这条消息，结果消费者挂了，这条消息就丢了。

例子：消费者消费到数据后写到一个内存 queue里缓存下，消息自动提交 offset，重启了系统，结果会导致内存 queue 里还没来得及处理的数据丢失。

解决方法：kafka会自动提交 offset，那么只要关闭自动提交 offset，在处理完之后自己手动提交，可以保证数据不会丢。但是此时确实还是会重复消费，比如刚好处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次 ，做好幂等即可。

- Kafka 丢掉消息

原因：kafka 某个 broker 宕机，然后重新选举 partition 的 leader时，此时其他的 follower 刚好还有一些数据没有同步，结果此时 leader挂了，然后选举某个 follower成 leader之后，就丢掉了之前leader里未同步的数据。

例子：kafka的leader机器宕机，将 follower 切换为 leader之后，发现数据丢了
解决方案：（保证 kafka broker端在 leader发生故障，或者leader切换时，数据不会丢）

- 给 topic设置 replication.factor ，这个值必须大于 1，保证每个 partition 必须至少有 2 个副本
- 在 kafka 服务端设置 min.insync.replicas 参数，这个值必须大于 1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保 leader挂了还有一个follower，保证至少一个 follower能和leader保持正常的数据同步。
- 在 producer 端设置 acks =all，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。否则会生产者会一直重试，此时设置 retries = MAX（很大的重试的值）,要求一旦写入失败，就卡在这里（避免消息丢失）

- kafka 生产者丢消息

设置了 ack =all，一定不会丢。它会要求 leader 接收到消息，所有的 follower 都同步 到了消息之后，才认为本次写成功。如果没满足这个条件，生产者会无限次重试 。

## 消息队列的顺序性

mysql binlog 同步的系统，在mysql里增删改一条数据，对应出来了增删改 3 条binlog，接着这 3 条binlog发送到 MQ 里面，到消费出来依次执行，起码是要保证顺序的吧，不然顺序变成了 删除、修改、增加。

乱序场景：

- rabbitmq,一个queue,多个consumer
- kafka,一个topic，一个partition,一个consumer，内部多线程

这种情况考虑线程之间的同步，多个consumer之间的同步

## 消息积压以及过期失效

常见：几千万条数据再 MQ 里积压了七八个小时，消息积压

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有的 consumer 都停掉
- 新建一个topic,partition是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数量
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue
- 接着临时征用 10 倍的机器来部署 consumer,每一批 consumer 消费一个临时 queue 的数据
- 这种做法相当 于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常 10 倍速度
- 等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的 consumer机器消费消息

如果用的 rabbitmq，并且设置了过期时间，如果此消费在 queue里积压超过一定的时间会被 rabbitmq清理掉，数据直接搞丢。
这个时候开始写程序，将丢失的那批数据查出来，然后重新mq里面，把白天丢的数据补回来。